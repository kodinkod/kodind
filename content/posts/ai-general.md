---
date: '2025-01-21T23:43:46+03:00'
draft: false
title: 'Ai General'
categories: ["AI"]
tags: ["Library"]
summary: "is all you need."
---



# Situational awareness

- Updated June 6, 2024б, [Situational awareness](https://situational-awareness.ai). 

>... Before long, the world will wake up. But right now, there are perhaps a few hundred people, most of them in San Francisco and the AI labs, that have situational awareness. Through whatever peculiar forces of fate, I have found myself amongst them. A few years ago, these people were derided as crazy—but they trusted the trendlines, which allowed them to correctly predict the AI advances of the past few years. Whether these people are also right about the next few years remains to be seen. But these are very smart people—the smartest people I have ever met—and they are the ones building this technology. Perhaps they will be an odd footnote in history, or perhaps they will go down in history like Szilard and Oppenheimer and Teller. If they are seeing the future even close to correctly, we are in for a wild ride ...

- January 21, 2025, [Announcing The Stargate Project](https://openai.com/index/announcing-the-stargate-project/) - company which intends to invest $500 billion over the next four years building new AI infrastructure for OpenAI in the United States.


# The Scaling Hypothesis

The **[The Scaling Hypothesis](https://gwern.net/scaling-hypothesis)** suggests that increasing the scale of neural networks (more parameters, data, and compute) improves their performance and ability to solve complex tasks. This idea is supported by models like GPT-3, which demonstrate meta-learning (few-shot learning) and generalization without complex architectures. The hypothesis implies that intelligence can emerge from simple algorithms applied at massive scales.


| **Aspect**               | **Description**                                                                                     | **Example/Evidence**                                                                 |
|--------------------------|-----------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|
| **Core Idea**            | Scaling up (parameters, data, compute) improves performance, even with simple architectures.       | GPT-3: 175B parameters, trained on internet text, demonstrates few-shot learning.   |
| **Meta-Learning**        | Models like GPT-3 can learn new tasks from few examples, showing generalization capabilities.       | GPT-3 solves arithmetic and translation tasks without specialized training.         |
| **Empirical Laws**       | Performance follows power laws: improvements depend on scale of parameters, data, and compute.     | OpenAI’s scaling laws: loss decreases with more parameters and data.                |
| **Criticism**            | Some argue scaling alone won’t lead to true AI, as models lack long-term memory or understanding.   | François Chollet (DeepMind) highlights limitations in data and architecture.        |
| **Future**               | If true, human-level AI may require millions of times more compute, achievable by the 2030s.       | Gwern’s prediction: AGI possible by 2038 with current compute growth rates.         |
| **Applications**         | Scaling enables powerful language models for science, business, and government, but risks misuse.  | GPT-3 can automate tasks or generate propaganda.                                    |

---


# ANI, AGI, ASI

to-be..